exp_name: "vit_large_16_224_LoRA"
seed: 369369
traindata_dir: './data/train'
testdata_dir: './data/test'

traindata_info_file: './data/train.csv'
testdata_info_file: './data/test.csv'

train_result_path: './train_result'
test_result_path: './output'

transform:
  transform_type: albumentations
  augmentations:
    - type: HorizontalFlip
      params:
        p: 0.5
    - type: VerticalFlip
      params:
        p: 0.5
    - type: Affine
      params:
        shear: [-10, 10]
        p: 0.5
    - type: RandomBrightnessContrast
      params:
        p: 0.5

    - type: Blur
      params:
        blur_limit: [3, 5]
        p: 0.5

device: 'cuda'

model_type: 'timm'
model_name: 'vit_large_patch16_224'
pretrained: true

loss: 'SmoothingLoss'

lora:
  use: true
  params:
    r: 8
    lora_alpha: 16
    lora_dropout: 0.1
    target_modules: '.*(attn.qkv|attn.proj|mlp.fc\d)'
    modules_to_save: ["head.fc"]

optimizer:
  type: AdamW
  params:
    lr: 0.001
    betas: [0.9, 0.999]
    eps: 1.0e-8
    amsgrad: False


scheduler:
  type: CosineAnnealingLR
  params:
    T_max: 10
    eta_min: 1.0e-6

num_epochs: 10
batch_size: 64