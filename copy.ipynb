{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Any, Callable, List, Optioanl, Union\n",
    "#Any랑 List랑 Optional은 필요없는건가?\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        info_df: pd.DataFrame,\n",
    "        transform: Callable, \n",
    "        is_inference: bool = False\n",
    "    ):\n",
    "        #데이터셋의 기본 경로, 이미지 변환 방법, 이미지 경로 및 레이블을 초기화한다.\n",
    "        self.root_dir = root_dir # 이미지 파일들이 저장된 기본 디렉토리\n",
    "        self.transform = transform # 이미지에 적용할 변환 처리\n",
    "        self.is_inference = is_inference # 추론을 할 것인지 확인한다.\n",
    "        self.image_paths = info_df['image_path'].tolist() # 이미지 파일 경로 목록\n",
    "\n",
    "        if not self.is_inference:\n",
    "            self.targets = info_df['target'].tolist() # 각 이미지에 대한 레이블 목록\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # 데이터셋의 총 이미지 수를 반환\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Union[Tuple[torch.Tensor, int], torch.Tensor]:\n",
    "        '''\n",
    "        특별메서드로, 객체에 대해서 []를 사용할 때 자동으로 호출된다.\n",
    "        index에는 int 값이 들어간다.\n",
    "        Union에는 여러 가능한 반환 타입 중 하나를 나타낸다.\n",
    "        Tuple[torch.Tensor, int]: torch.Tensor나 int 값을 반환할 수 있다.\n",
    "        torch.Tensor: 단일로 Tensor만 반환할 수 있다.\n",
    "        \n",
    "        정리하면, Union은 Tuple[torch.Tensor, int]를 반환하거나, torch.Tensor을 반환한다.\n",
    "        '''\n",
    "        img_path = os.path.join(self.root_dir, self.image_paths[index]) # 인덱스별 파일의 이미지 경로 위치를 구한다.\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR) # 이미지를 BGR 컬러 포맷의 numpy array로 읽어온다.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGE 포맷을 RGB 포맷으로 변환\n",
    "        image = self.transform(image) # 설정한 transform으로 이미지 변환\n",
    "\n",
    "        if self.is_inference:\n",
    "            return image #torch.Tensor 형태\n",
    "        else:\n",
    "            target = self.targets[index] # 해당 이미지의 레이블\n",
    "            return image, target # 변환된 이미지와 레이블을 Tuple[torch.Tensor, int]이런 형태로 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, is_train: bool=True, transform_config: str=None):\n",
    "        # 공통 변환 설정: 리사이즈, 정규화, 텐서 변환 (train이랑 test 둘 다)\n",
    "        common_transforms = [\n",
    "            A.resize(224,224),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.224]),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "\n",
    "        if is_train:\n",
    "            #훈련용 변환\n",
    "            self.transform = A.Compose(self._create_augmentations(transform_config) + common_transforms)\n",
    "        else:\n",
    "            # 검증, 테스트 용 변환\n",
    "            self.transform = A.Compose(common_transforms)\n",
    "\n",
    "    def _create_augmentations(self, augmentations):\n",
    "        # 입력 받은 augmentations로 인자를 list 형태로 변환\n",
    "        aug_list = []\n",
    "        for aug in augmentations:\n",
    "            aug_class = getattr(A, aug[\"type\"]) # A.HorizontalFlip이나, A.Rotate로 만들어준다.\n",
    "            \n",
    "            # 객체를 생성해서 list에 추가.\n",
    "            aug_list.append(aug_class(**aug[\"params\"])) # A.HorizontalFlip()매개 변수 적용\n",
    "        return aug_list\n",
    "\n",
    "    def __call__(self, image) -> torch.Tensor:\n",
    "        #이미지가 numpy 배열인지 확인\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise TypeError(\"Image should be a Numpy array (OpenCV format).\")\n",
    "        \n",
    "        transformed = self.transform(image=image)\n",
    "\n",
    "        # 결과는 딕셔너리로 반환 됨.\n",
    "        return transformed['image'] # 이미지 외에 마스크나 바운딩 박스도 넣을 수 있다.\n",
    "\n",
    "class TransformSelector:\n",
    "    '''\n",
    "    이미지 변환 라이브러리를 선택하기 위한 클래스\n",
    "    '''\n",
    "    def __init__(self, transform_type: str, transform_config: str=None):\n",
    "\n",
    "        # 지원하는 라이브버리인지 확인\n",
    "        if transform_type in ['albumentations']:\n",
    "            self.transform_type = transform_type\n",
    "            self.tranform_config = transform_config\n",
    "        else:\n",
    "            raise ValueError(\"Unknown transformation library specified\")\n",
    "        \n",
    "    def get_transform(self, is_train: bool):\n",
    "        \n",
    "        #선택한 라이브러리에 따라 적절한 변환 객체를 생성\n",
    "        if self.transform_type == 'albumentations':\n",
    "            transform = AlbumentationsTransform(is_train=is_train, transform_config=self.transform_config)\n",
    "\n",
    "        return transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CELoss(nn.Module):\n",
    "\n",
    "    # super().__init__()와 같지만, 좀 더 명시적인 표현\n",
    "    def __init__(self):\n",
    "        super(CELoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            outputs: torch.Tensor,\n",
    "            targets: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        return self.loss_fn(outputs, targets)\n",
    "\n",
    "class SmoothingLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SmoothingLoss, self).__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            outputs: torch.Tensor,\n",
    "            targets: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        return self.loss_fn(outputs, targets)\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        '''\n",
    "        alpha: 클래스 불균형 조정을 위한 가중치\n",
    "        gamma: \n",
    "        reduction: 손실 값을 처리하는 방식\n",
    "        '''\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "\n",
    "        # Cross entropy loss 계산\n",
    "        BCE_loss = F.cross_entropy(outputs, targets, reduction='none', label_smoothing=0.1)\n",
    "\n",
    "        # 예측 확률을 계산\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "\n",
    "        # Focal Loss 계산\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            # none, 샘블별 손실을 유지하면서 반환\n",
    "            # 샘플별로, 상위 10% 손실값만 사용하는 등의 활용이 가능하다.\n",
    "            return F_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "class TorchvisionModel(nn.Module):\n",
    "    '''\n",
    "    Torchvision에서 제공하는 사전 훈련된 모델을 사용하는 클래스\n",
    "    '''\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            num_classes: int,\n",
    "            pretrained: bool\n",
    "    ):\n",
    "        super(TorchvisionModel, self).__init__()\n",
    "        #model.(원하는 모델)(파라미터)를 가지고 옴.\n",
    "        self.model = models.__dict__[model_name](pretrained=pretrained)\n",
    "        \n",
    "\n",
    "        # 모델의 최종 분류기 부분을 사용자 정의 클래스 수에 맞게 조정\n",
    "        #'fc' (Fully Connected): ResNet, VGG 등의 모델에서 주로 사용\n",
    "        # dir: 객체의 모든 속성과 메서드 이름을 리스트로 반환\n",
    "        if 'fc' in dir(self.model):\n",
    "            # self.model.fc는 모델의 마지막 입력 특성 수\n",
    "            # self.model.fc.in_features는 이 계층의 입력 특성 수\n",
    "            num_ftrs = self.model.fc.in_features\n",
    "            # 마지막 계층의 outputs을 클래스 수에 맞게 조정\n",
    "            self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "        #'classifier': DenseNet, MobileNet 등의 일부 모델에서 사용\n",
    "        elif 'classifier' in dir(self.model):\n",
    "            # [-1]로 마지막 계층으로 이동\n",
    "            num_ftrs = self.model.classifier[-1].infeatures\n",
    "            self.model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    간단한 CNN 아키텍처를 정의하는 클래스.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # 순전파 함수 정의\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class TimmModel(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            num_classes: int,\n",
    "            pretrained: bool\n",
    "    ):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_claess=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        return self.model(x)\n",
    "    \n",
    "class ModelSelector:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_type: str,\n",
    "            num_classes: int,\n",
    "            **kwargs\n",
    "    ):\n",
    "        # 모델 유형에 따라 적절한 모델 객체를 생성\n",
    "        if model_type == 'simple':\n",
    "            self.model = SimpleCNN(num_classes=num_classes)\n",
    "\n",
    "        elif model_type == 'torchvision':\n",
    "            self.model = TorchvisionModel(num_classes=num_classes, **kwargs)\n",
    "        elif model_type == 'timm':\n",
    "            self.model = TimmModel(num_classes=num_classes, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown model type specified\")\n",
    "                 \n",
    "    def get_model(self) -> nn.Module:\n",
    "\n",
    "        return self.model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,       \n",
    "        model: nn.Module,\n",
    "        device: torch.device,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        optimizer: optim.optimizer,\n",
    "        scheduler: optim.lr_scheduler,\n",
    "        loss_fn: torch.nn.modules.loss._Loss,\n",
    "        epochs: int,\n",
    "        result_path: str,\n",
    "        exp_name: str,\n",
    "        patience: int,\n",
    "        min_delta: str,\n",
    "        mine_delta: float,\n",
    "        config_path: str\n",
    "    ):\n",
    "        # 클래스 초기화: 모델, 디바이스, 데이터 로더 등 설정\n",
    "        self.model = model  # 훈련할 모델\n",
    "        self.device = device  # 연산을 수행할 디바이스 (CPU or GPU)\n",
    "        self.train_loader = train_loader  # 훈련 데이터 로더\n",
    "        self.val_loader = val_loader  # 검증 데이터 로더\n",
    "        self.optimizer = optimizer  # 최적화 알고리즘\n",
    "        self.scheduler = scheduler # 학습률 스케줄러\n",
    "        self.loss_fn = loss_fn  # 손실 함수\n",
    "        self.epochs = epochs  # 총 훈련 에폭 수\n",
    "        # ES 조기종료를 위한 추가\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "    \n",
    "        # 저장경로 생성\n",
    "        self.result_path = os.path.join(result_path, exp_name)\n",
    "        os.makedir(self.result_path, exist_ok=False)\n",
    "\n",
    "        shutil.copyfile(config_path, os.path.join(self.result_path, 'config.yaml'))\n",
    "\n",
    "        # 텐서보드의 summaryWriter 설정\n",
    "        self.weriter = SummaryWriter(log_dir=self.result_path)\n",
    "\n",
    "        self.best_models = [] # 상위 3개의 모델 정보를 저장하는 리스트\n",
    "        self.lowest_loss = float('inf') # 가장 낮은 Loss를 저장할 변수\n",
    "\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        # 모델 저장 경로 설정\n",
    "        current_model_path = os.path.join(self.result_path, f'model_epoch_{epoch}_loss_{loss:.4f}.pt')\n",
    "        torch.save(self.model.state_dict(), current_model_path)\n",
    "        \n",
    "        # 최상위 3개 모델 관리\n",
    "        self.best_models.append((loss, epoch, current_model_path))\n",
    "        self.best_models.sort()\n",
    "        if len(self.best_models) > 3:\n",
    "            _, _, path_to_remove = self.best_models.pop(-1)  # 가장 loss가 높은 모델 삭제\n",
    "            if os.path.exists(path_to_remove):\n",
    "                os.remove(path_to_remove)\n",
    "        \n",
    "        # 가장 낮은 손실의 모델 저장\n",
    "        if loss < self.lowest_loss:\n",
    "            self.lowest_loss = loss\n",
    "            best_model_path = os.path.join(self.result_path, 'best_model.pt')\n",
    "            torch.save(self.model.state_dict(), best_model_path)\n",
    "            print(f'save {epoch} epoch result. Loss = {loss:.4f}')\n",
    "\n",
    "    def train_epoch(self) -> float:\n",
    "        \n",
    "        # 한 에폭 동안의 훈련을 관리\n",
    "        self.model.train()\n",
    "        \n",
    "        total_loss = 0.0\n",
    "        #tqdm으로 훈련과정을 시각화 \n",
    "        # self.train_loader: 각 배치의 진행 상황\n",
    "        # desc: Traning이라는 설명 추가\n",
    "        # 훈련과정이 프로그레스바 삭제\n",
    "        progress_bar = tqdm(self.train_loader, desc=\"Traning\", leave=False)\n",
    "        # AMP를 위한 Gradscaler 객체 생성\n",
    "        scaler = torch.amp.Gradscaler('cuda')\n",
    "\n",
    "        for batch_idx, (images, targets) in enumerate(progress_bar):\n",
    "            images, targets = images.to(self.device), targets.to(self.device)\n",
    "            # optimizer에 등록된 모든 파라미터의 gradient를 초기화\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # AMP로, 여기서만 float16으로 계산\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = self.model(images)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(self.optimizer)\n",
    "            scaler.update()\n",
    "            self.scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        return total_loss / len(self.trainloader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
